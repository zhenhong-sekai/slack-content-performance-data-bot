version: '3.8'

services:
  # Main application - production configuration
  slack-bot:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - ENVIRONMENT=production
      - DEBUG=false
      - LOG_LEVEL=INFO
      - REDIS_URL=redis://redis:6379/0
      - TEMP_FILE_PATH=/app/temp_files
      - METRICS_PORT=8001
    env_file:
      - .env.production
    volumes:
      - temp_files:/app/temp_files
      - app_logs:/app/logs
    depends_on:
      redis:
        condition: service_healthy
    restart: always
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Load balancer
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
      - app_logs:/var/log/nginx
    depends_on:
      - slack-bot
    restart: always

  # Socket Mode workers (replaces webhook processing)
  socket-mode-worker:
    build:
      context: .
      dockerfile: Dockerfile
    command: ["python", "-m", "src.workers.socket_mode_worker"]
    environment:
      - ENVIRONMENT=production
      - DEBUG=false
      - LOG_LEVEL=INFO
      - REDIS_URL=redis://redis:6379/0
    env_file:
      - .env.production
    depends_on:
      redis:
        condition: service_healthy
    restart: always
    deploy:
      replicas: 1  # Only one Socket Mode connection needed
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  # Agent processor workers
  agent-processor:
    build:
      context: .
      dockerfile: Dockerfile
    command: ["python", "-m", "src.workers.agent_processor"]
    environment:
      - ENVIRONMENT=production
      - DEBUG=false
      - LOG_LEVEL=INFO
      - REDIS_URL=redis://redis:6379/0
      - TEMP_FILE_PATH=/app/temp_files
    env_file:
      - .env.production
    volumes:
      - temp_files:/app/temp_files
    depends_on:
      redis:
        condition: service_healthy
    restart: always
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # Redis cluster for high availability
  redis:
    image: redis:7-alpine
    command: >
      redis-server
      --appendonly yes
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
      --tcp-keepalive 60
      --timeout 300
    volumes:
      - redis_data:/data
    restart: always
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3

  # Redis Sentinel for Redis monitoring
  redis-sentinel:
    image: redis:7-alpine
    command: redis-sentinel /etc/redis/sentinel.conf
    volumes:
      - ./redis/sentinel.conf:/etc/redis/sentinel.conf
    depends_on:
      - redis
    restart: always

  # File cleanup service
  file-cleanup:
    build:
      context: .
      dockerfile: Dockerfile
    command: >
      sh -c "while true; do 
        python -c 'import asyncio; from src.services.csv_service import get_csv_service; asyncio.run(get_csv_service().cleanup_expired_files())';
        sleep 3600;
      done"
    environment:
      - ENVIRONMENT=production
      - TEMP_FILE_PATH=/app/temp_files
    volumes:
      - temp_files:/app/temp_files
    restart: always

  # Monitoring and metrics
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.prod.yml:/etc/prometheus/prometheus.yml
      - ./monitoring/rules:/etc/prometheus/rules
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    restart: always

  # Grafana for dashboards
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/prod-dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    restart: always

  # Log aggregation
  fluentd:
    image: fluent/fluentd:v1.16-debian
    volumes:
      - ./logging/fluent.conf:/fluentd/etc/fluent.conf
      - app_logs:/var/log
    ports:
      - "24224:24224"
      - "24224:24224/udp"
    restart: always

volumes:
  redis_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  temp_files:
    driver: local
  app_logs:
    driver: local

networks:
  default:
    driver: bridge